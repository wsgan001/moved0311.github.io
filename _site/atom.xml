<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>Note</title>
 <link href="http://localhost:4000/atom.xml" rel="self"/>
 <link href="http://localhost:4000/"/>
 <updated>2017-03-27T17:16:54+08:00</updated>
 <id>http://localhost:4000</id>
 <author>
   <name>Taiyi</name>
   <email>moved0311@gmail.com</email>
 </author>

 
 <entry>
   <title>Data Structure</title>
   <link href="http://localhost:4000/2017/dataStructure/"/>
   <updated>2017-03-27T00:00:00+08:00</updated>
   <id>http://localhost:4000/2017/dataStructure</id>
   <content type="html">&lt;h2 id=&quot;linklist&quot;&gt;LinkList&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;linklist reverse&lt;/strong&gt;&lt;br /&gt;
&lt;img src=&quot;/img/dataStructure/linkListReverse.png&quot; alt=&quot;linkListReverse&quot; /&gt;
&lt;!--more--&gt;
    &lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;linkListReverse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Node&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;head&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Node&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tail&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Node&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Node&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;

      &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Node&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;insert&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;Node&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Node&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;val&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;next&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;tail&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;next&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; 
              &lt;span class=&quot;n&quot;&gt;tail&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;head&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;tail&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; 
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Node&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;Node&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;val&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot; -&amp;gt; &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;   
              &lt;span class=&quot;n&quot;&gt;iter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;null&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Node&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;reverse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Node&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;Node&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pre&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;Node&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;current&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;Node&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;next&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;current&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
             &lt;span class=&quot;n&quot;&gt;next&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;current&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
             &lt;span class=&quot;n&quot;&gt;current&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;next&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pre&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;  
             &lt;span class=&quot;n&quot;&gt;pre&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;current&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
             &lt;span class=&quot;n&quot;&gt;current&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;   
          &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pre&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
        
      &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++){&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;Node&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;insert&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;before reverse:&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;Node&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;Node&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reverseHead&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Node&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;reverse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;After reverse:&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;Node&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reverseHead&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>python</title>
   <link href="http://localhost:4000/2017/python/"/>
   <updated>2017-03-08T00:00:00+08:00</updated>
   <id>http://localhost:4000/2017/python</id>
   <content type="html">&lt;h4 id=&quot;print&quot;&gt;print&lt;/h4&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%.2&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h4 id=&quot;註解&quot;&gt;註解&lt;/h4&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 單行&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# -*- coding: utf-8 -*-&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 多行&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
&quot;&quot;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h4 id=&quot;date-and-time&quot;&gt;Date and Time&lt;/h4&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;datetime&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datetime&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;now&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datetime&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;now&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;now&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h4 id=&quot;input&quot;&gt;input&lt;/h4&gt;
&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;raw_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;What is your name?&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>WebSearching</title>
   <link href="http://localhost:4000/2017/webSearching/"/>
   <updated>2017-03-07T00:00:00+08:00</updated>
   <id>http://localhost:4000/2017/webSearching</id>
   <content type="html">&lt;p&gt;&lt;strong&gt;CH8 Evaluation in information retrival&lt;/strong&gt;  &lt;br /&gt;
評量search engine好壞&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;搜到的index&lt;/li&gt;
  &lt;li&gt;搜尋速度&lt;/li&gt;
  &lt;li&gt;二氧化碳排放量&lt;/li&gt;
  &lt;li&gt;和搜尋相關程度&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;相關程度&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;benchmark資料集&lt;/li&gt;
  &lt;li&gt;benchmark queries(問句)&lt;/li&gt;
  &lt;li&gt;文章是否相關的標記(ground truths)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;queries和information need有落差
想找的東西,不會下key word&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Precision (P)&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Precision = &lt;script type=&quot;math/tex&quot;&gt;\frac{檢索到相關物件的數量}{物件總數}\&lt;/script&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Recall (R)&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Recall = &lt;script type=&quot;math/tex&quot;&gt;\frac{檢索到相關物件的數量}{相關物件總數}\&lt;/script&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Relevant&lt;/td&gt;
      &lt;td&gt;Nonrelevent&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Retrieved&lt;/td&gt;
      &lt;td&gt;true positive(tp)&lt;/td&gt;
      &lt;td&gt;false positive(fp)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Not retrieved&lt;/td&gt;
      &lt;td&gt;false negatives(fn)&lt;/td&gt;
      &lt;td&gt;true negatives(tn)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;true positive(tp) 機器判斷+且為真&lt;br /&gt;
false positive(fp)機器判斷+但是是假&lt;br /&gt;
false negatives(fn) 機器判斷-但判斷錯&lt;br /&gt;
true negatives(tn)  機器判斷-且判斷對&lt;/p&gt;

&lt;p&gt;P = &lt;script type=&quot;math/tex&quot;&gt;\frac{tp}{tp+fp}\&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;R = &lt;script type=&quot;math/tex&quot;&gt;\frac{tp}{tp+fn}\&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Accuracy vs Precision&lt;/strong&gt; &lt;br /&gt;
accuracy = &lt;script type=&quot;math/tex&quot;&gt;\frac{tp+tn}{tp+fp+fn+tn}\&lt;/script&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;accuracy不適合用在information retrieval,
因為通常Nonrelevant會非常的大,tn項非常大除分母fn和tn都非常大結果會趨近於1,所以才用Precision和Recall作為依據&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;調和平均數(harmonic mean)&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;H = &lt;script type=&quot;math/tex&quot;&gt;\frac{n}{\frac{1}{x_1}+\frac{1}{x_2}+..+\frac{1}{x_n}}\&lt;/script&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Precision/Recall Tradoff
使用調和平均數計算Precision和Recall的Tradoff&lt;br /&gt;
量測的數值稱做F measure,α和1-α分別為P和R的權重,一般是取α=0.5&lt;br /&gt;
(P和R重要程度相同)&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;F = &lt;script type=&quot;math/tex&quot;&gt;\frac{1}{\alpha\frac{1}{P}+(1-\alpha)\frac{1}{R}} = \frac{(\beta^2+1)PR}{\beta^2P+R}\&lt;/script&gt; where &lt;script type=&quot;math/tex&quot;&gt;\ \beta^2=\frac{1-\alpha}{\alpha}\&lt;/script&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;ranked-evalution&quot;&gt;Ranked Evalution&lt;/h4&gt;
&lt;p&gt;P,R,F都是unordered(沒有等級)&lt;br /&gt;
一個query會有一個Precision/Recall圖(崎嶇的坡)  &lt;br /&gt;
使用內插法(interpolated)可以得到一張較平滑的P-R圖(和機器學習ROC curve相似)
P-R curve的面積越大效能越佳(代表Precision掉越慢)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;內插法&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;script type=&quot;math/tex; mode=display&quot;&gt;\ p_{interp}= \max\limits_{r'\ge r}\ p(r{'})\&lt;/script&gt;
&lt;/blockquote&gt;

&lt;p&gt;r代表recall,
作法是從目前往後找最高的點向前填平,並重新畫P-R圖&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Mean Average Precision(MAP)&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;script type=&quot;math/tex; mode=display&quot;&gt;\ MAP(Q) = \frac{1}{|Q|}\sum^{|Q|}_{j=1}\frac{1}{m_j}\sum_{k=1}^{m_j}Precision(R_{jk})\&lt;/script&gt;
&lt;/blockquote&gt;

&lt;p&gt;第一個sum算query平均&lt;br /&gt;
第二個sum算precision平均&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Precision at k&lt;/strong&gt;&lt;br /&gt;
第k個搜索結果的Precision&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;R-Precision&lt;/strong&gt;&lt;br /&gt;
文件中總共有R篇相關文章,以R作為cut-off,計算Precision&lt;br /&gt;
e.g. 總共有100篇文章,其中10篇是相關的&lt;br /&gt;
且搜尋結果是:RNRNN RRNNN RNNRR ….&lt;br /&gt;
R=10(只看RNRNN RRNNN)計算Precision&lt;br /&gt;
R-Precision = 0.4&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Normalized Discounted Cumulative Gain(NDCG)&lt;/strong&gt;  &lt;br /&gt;
作者：Kalervo Jarvelin, Jaana Kekalainen(2002)&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;用來衡量ranking quality&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;e.g.&lt;br /&gt;
G = &amp;lt;3,2,3,0,0,1,2,2,3,0,…&amp;gt; &lt;br /&gt;
G表示一個搜索的結果(3高度相關, 0沒關係)&lt;br /&gt;
步驟:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Cumulative Gain(CG)
    &lt;blockquote&gt;

      &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\
 CG[i] = \left\{\begin{matrix}
 G[1], &amp;if\ i=1 \\ 
 CG[i-1]+G[i], &amp;otherwise 
 \end{matrix}\right.
 \ %]]&gt;&lt;/script&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;目前項+＝前一項(做成一個遞增的函數)&lt;br /&gt;
 CG’=&amp;lt;3,5,8,8,8,9,11,13,16,16,…&amp;gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Discounted Cumulative Gain(DCG)
    &lt;blockquote&gt;

      &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\
 DCG[i]=\left\{\begin{matrix}
 G[i], &amp; if\ i=1\\ 
 DCG[i-1]+G[i]/log_b\ i, &amp; otherwise
 \end{matrix}\right.
 \ %]]&gt;&lt;/script&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;DCG’=&amp;lt;3,5,6.89,6.89,6.89,7.28,7.99,8.66,9.61,9.61,…&amp;gt; if b=2&lt;br /&gt;
 i代表排名,對排名做懲罰(除log&lt;sub&gt;2&lt;/sub&gt; i),排名越後面懲罰越重&lt;br /&gt;
 代表如果搜尋的結果很差,和理想的排序分數會相差很多&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Normalized Discounted Cumulative Gain(NDCG)&lt;br /&gt;
 理想的搜索結果I=&amp;lt;3,3,3,2,2,2,1,1,1,1,0,0,0,…&amp;gt;(高度相關的排越前面) &lt;br /&gt;
 理想搜索結果DCGI=&amp;lt;3,6,7.89,8.89,9.75,10.52,10.88,11.21,…&amp;gt;&lt;br /&gt;
 nDCG&lt;sub&gt;n&lt;/sub&gt; = &lt;script type=&quot;math/tex&quot;&gt;\ \frac{DCG_{n}}{IDCG_{n}}(\frac{相關程度排序}{理想相關程度},做正規化)\&lt;/script&gt;&lt;br /&gt;
 NDCG=&amp;lt;1,0.83,0.87,0.77,0.70,0.69,0.73,0.77,…&amp;gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;benchmark 資料集&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Cranfield&lt;/li&gt;
  &lt;li&gt;TREC(nist.gov)&lt;br /&gt;
 Ad-hoc 資料集(1992-1999)&lt;/li&gt;
  &lt;li&gt;GOV2
 2500萬篇文章&lt;/li&gt;
  &lt;li&gt;NICIR
 cross-language IR&lt;/li&gt;
  &lt;li&gt;Cross Language Evaluation&lt;/li&gt;
  &lt;li&gt;REUTERS&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;標記資料準則&lt;/strong&gt; &lt;br /&gt;
Kappa measure&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;標記資料是否一致的衡量標準,若標記不一致資料中就沒有truth&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Kappa計算公式&lt;/p&gt;
&lt;blockquote&gt;
  &lt;script type=&quot;math/tex; mode=display&quot;&gt;\ \kappa = \frac{P(A)-P(E)}{1-P(E)}\&lt;/script&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Result Summaries&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;搜尋結果呈現：10 blue link&lt;/li&gt;
  &lt;li&gt;搜尋結果下方文字說明分為Static和Dynamic
Static:固定抽前50個字
Dynamic:利用nlp技術,根據搜索關鍵字動態做變化&lt;/li&gt;
  &lt;li&gt;quicklinks&lt;br /&gt;
底下多的連結&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Ch6 Model&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Vector Space Model&lt;/li&gt;
  &lt;li&gt;Probabilistic Information Retrieval&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Empirical IR&lt;/td&gt;
      &lt;td&gt;Model-based IR&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;暴力法&lt;/td&gt;
      &lt;td&gt;有理論模型&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;heuristic&lt;/td&gt;
      &lt;td&gt;數學假設&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;難推廣到其他問題&lt;/td&gt;
      &lt;td&gt;容易推廣到其他問題&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;IR model歷史&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;1960&lt;br /&gt;
  第一個機率模型&lt;/li&gt;
  &lt;li&gt;1970   &lt;br /&gt;
  vector space model(75)  &lt;br /&gt;
  classic probabilistic model(76)&lt;/li&gt;
  &lt;li&gt;1980&lt;br /&gt;
  non-class logic model(86)&lt;/li&gt;
  &lt;li&gt;1990&lt;br /&gt;
  TREC benchmark &lt;br /&gt;
  BM25/Okapi(94)&lt;br /&gt;
  google成立(96)  &lt;br /&gt;
  Language model(98)&lt;/li&gt;
  &lt;li&gt;2000&lt;br /&gt;
  Axiomatic model(04)&lt;br /&gt;
  Markov Random Field(05)   &lt;br /&gt;
  Learning to rank(05)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Vector space&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Vocabulary&lt;/td&gt;
      &lt;td&gt;V = { &lt;script type=&quot;math/tex&quot;&gt;w_1,w_2,w_3,...w_v&lt;/script&gt; }&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Query&lt;/td&gt;
      &lt;td&gt;q =&lt;script type=&quot;math/tex&quot;&gt;\{q_1,q_2,...,q_m\}&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Document 文章&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt;{d_i} = \{  w_1,w_2,...  \}&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Collection文章集合&lt;/td&gt;
      &lt;td&gt;C = { &lt;script type=&quot;math/tex&quot;&gt;d_1,d_2,d_3,...&lt;/script&gt; }&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;R(q) query的集合&lt;/td&gt;
      &lt;td&gt;R(q) ⊂ C&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;目標是找到近似query的集合&lt;/strong&gt;&lt;br /&gt;
策略:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Document select&lt;br /&gt;
 挑文件如果是相關就收到集合&lt;br /&gt;
 absolute relevance(系統必須決定是相關還是不相關)&lt;/li&gt;
  &lt;li&gt;Document ranking&lt;br /&gt;
 query的結果&amp;gt;threshold 就收進去  &lt;br /&gt;
 relative relevance(不必是1或0,相近到一定程度就收進集合)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Probability Ranking Principle(PRP)&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Robertson (1977)&lt;br /&gt;
相似度量測函數f滿足,&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;f(q,d_1) &gt; f(q,d_2)\quad iff\quad p(Rel|q,d_1) &gt; p(Rel|q,d_2)&lt;/script&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The notation of Relevance&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Relevance
    &lt;ul&gt;
      &lt;li&gt;Similarity 相似度&lt;br /&gt;
   Vector space model&lt;/li&gt;
      &lt;li&gt;Probability of relevance 機率模型&lt;/li&gt;
      &lt;li&gt;Probability inference 機率推論&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Vector Space Model(VSM)&lt;/strong&gt;&lt;br /&gt;
將query和document表示成向量形式(similar representation)&lt;br /&gt;
假設Relevance(d,q) = similar(d,q)&lt;br /&gt;
利用cosine算相似度(1 ~ -1) &lt;br /&gt;
high dimension(index的維度通常在10萬左右) &lt;br /&gt;
good dimension -&amp;gt; orthogonal&lt;br /&gt;
(好的維度切割應該是維度間彼此獨立(orthogonal),&lt;br /&gt;
但是通常很困難,例如nccu後面接university的機率很高)&lt;br /&gt;
VSM優點: Empirically effective,直觀, 實作容易&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;VectorSpace範例程式&lt;/strong&gt;&lt;br /&gt;
&lt;a href=&quot;http://blog.josephwilk.net/projects/building-a-vector-space-search-engine-in-python.html&quot;&gt;Building a Vector Space Search Engine in Python&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;大致步驟&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;將所有文章使用join()成為一個string包含所有文章內容&lt;/li&gt;
  &lt;li&gt;做string clean去除. , 多餘空白,並轉為小寫&lt;/li&gt;
  &lt;li&gt;將clean好的string利用空白切分成words array,丟到Porter stem(去除字尾)
    &lt;blockquote&gt;
      &lt;p&gt;Porter Stemming Algorithm&lt;br /&gt;
    作者:Martin Porter(2006)&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;刪除重複的word,使用set讓出現的word唯一&lt;/li&gt;
  &lt;li&gt;得到所有整理完的words,做成index(將每個word編號)&lt;/li&gt;
  &lt;li&gt;將每篇文章分別建立自己的index,並統計每個word出現的次數&lt;/li&gt;
  &lt;li&gt;將輸入的query做成vector&lt;/li&gt;
  &lt;li&gt;利用計算相關程度&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;index值使用TF-IDF&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;TF(Term Frequency)&lt;br /&gt;
  word count,單純統計字數出現頻率&lt;/li&gt;
  &lt;li&gt;IDF(Inverse Document Frequency)(反向的TF)&lt;br /&gt;
  字的獨特性,如果某些字在很多篇文章出現次數都很高  &lt;br /&gt;
  例如:the,a,to,…&lt;br /&gt;
  IDF值就會很低(沒有鑑別度)	&lt;br /&gt;
  IDF(t) = 1 + log(n/k)  (n:篇數,k:字出現次數)&lt;br /&gt;
  例如文章總數是1000(n=1000),所有文章都有出現cat(k=1000),&lt;br /&gt;
  IDF = 1 + log(1000/1000) = 1&lt;br /&gt;
  如果只有1篇文章有出現cat,&lt;br /&gt;
  IDF = 1 + log(1000/1) = 4&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;TF-IDF計算方法:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;weight(t,d) = TF(t,d) * IDF(t)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;TF-IDF範例程式&lt;/strong&gt;&lt;br /&gt;
&lt;a href=&quot;http://stevenloria.com/finding-important-words-in-a-document-using-tf-idf/&quot;&gt;Tutorial: Finding Important Words in Text Using TF-IDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;下禮拜講Ch11&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>SocialCloudComputing</title>
   <link href="http://localhost:4000/2017/cloudComputing/"/>
   <updated>2017-02-25T00:00:00+08:00</updated>
   <id>http://localhost:4000/2017/cloudComputing</id>
   <content type="html">&lt;h4 id=&quot;課程簡介&quot;&gt;課程簡介&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Centrality Analysis&lt;/li&gt;
  &lt;li&gt;Community Detection&lt;/li&gt;
  &lt;li&gt;Link Prediction&lt;/li&gt;
  &lt;li&gt;Label Prediction&lt;/li&gt;
  &lt;li&gt;Influence maximization&lt;/li&gt;
  &lt;li&gt;Outbreak Detection&lt;br /&gt;
消息擴散路徑&lt;/li&gt;
  &lt;li&gt;Role/Postion Analysis&lt;/li&gt;
  &lt;li&gt;Social Relation Extraction&lt;/li&gt;
  &lt;li&gt;Cloud Computing
&lt;!--more--&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;journals&quot;&gt;Journals&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Nature&lt;/li&gt;
  &lt;li&gt;Science&lt;/li&gt;
  &lt;li&gt;Physical Review&lt;/li&gt;
  &lt;li&gt;Social Networks&lt;/li&gt;
  &lt;li&gt;ACM Transactions on Knowledge Discovery from Data (TKDD)&lt;/li&gt;
  &lt;li&gt;ACM Transactions on Intelligent Systems and Technology(TIST)&lt;/li&gt;
  &lt;li&gt;ACM Transactions on Social Computing(TSC)&lt;/li&gt;
  &lt;li&gt;IEEE Transactions on Knowledge and Data Engineering(TKDE)&lt;/li&gt;
  &lt;li&gt;IEEE Transactions on Computational Social System&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;social-networks&quot;&gt;Social Networks&lt;/h4&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Sociocentric&lt;/td&gt;
      &lt;td&gt;Egocentric&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;根據整群分析&lt;/td&gt;
      &lt;td&gt;根據個人分析,向外延伸&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
  &lt;li&gt;information Network&lt;br /&gt;
paper reference&lt;br /&gt;
web hyperlink&lt;br /&gt;
Language&lt;/li&gt;
  &lt;li&gt;Social Network&lt;br /&gt;
FB好友關係&lt;/li&gt;
  &lt;li&gt;Technology Network&lt;br /&gt;
電力系統(Power grid)&lt;/li&gt;
  &lt;li&gt;Biologycal Network&lt;br /&gt;
蛋白質互動關係,食物鏈&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;為什麼要分這麼多類Network?&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;因為要分析的點不同,可能在information Network中很重要的,卻在Social Network可能不是那麼重要&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;**&lt;/em&gt; Network Properties&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;small-world effect
 六度分離理論&lt;br /&gt;
 靠點和點距離關係分析&lt;/li&gt;
  &lt;li&gt;Transitivity
 朋友的朋友很可能也是你朋友&lt;br /&gt;
 &lt;a href=&quot;https://zh.wikipedia.org/wiki/%E9%9B%86%E8%81%9A%E7%B3%BB%E6%95%B0&quot;&gt;Clustering Coeffieient&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Degree distribution
 Real world network: Power law		
 P&lt;sub&gt;k&lt;/sub&gt; = CK&lt;sup&gt;-α&lt;/sup&gt;&lt;br /&gt;
 Heavy-tailed degree distribution&lt;br /&gt;
 大量很低的數量,集合起來還是很驚人&lt;/li&gt;
  &lt;li&gt;Network resilience
 如果拿掉一些點/邊,連通性會有什麼變化？(e.g.有些人掛了,離職)&lt;br /&gt;
 連接path的長度變長,或是disconnect &lt;br /&gt;
 廣告投放要投在哪個點影響力最大,如果是傳染病隔離哪個點最有效?&lt;/li&gt;
  &lt;li&gt;Mixing patterns&lt;br /&gt;
 探討兩邊節點的type,可能因為什麼關係成為朋友(職業/興趣/文化)&lt;/li&gt;
  &lt;li&gt;Degree Correlations
 觀察兩邊點的degree&lt;br /&gt;
 內向和外向人(朋友多,degree高)觀察&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Community Structure 
 一群點邊的密度很高,稱作一個community  &lt;br /&gt;
 clique 判斷是否認兩個點是否都有邊相連(clique problem 分團問題)&lt;br /&gt;
 clique problem 是 NP-Complete&lt;/p&gt;

    &lt;p&gt;Connected commponets :有連通的子圖&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Network motifs    &lt;br /&gt;
在音樂上motifs是一種作曲法,靈感的意思&lt;br /&gt;
 在生物基因上是一些重複的pattern&lt;br /&gt;
 在社群希望找到出現次數較高的motifs(最常出現的subgraph)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;CERN
&lt;a href=&quot;https://zh.wikipedia.org/wiki/%E7%B1%B3%E7%88%BE%E6%A0%BC%E5%80%AB%E5%AF%A6%E9%A9%97&quot;&gt;米爾格倫實驗 Milgram experiment&lt;/a&gt;服從威權實驗 &lt;br /&gt;
random graph&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Central of Network&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;找到最重要的點(central)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;local&lt;/p&gt;
&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;Degree&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;global&lt;/p&gt;
&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;Closeness&lt;/li&gt;
    &lt;li&gt;Betweeness&lt;/li&gt;
    &lt;li&gt;Eigenvector&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Group Centrality 一群最有影響力的人&lt;br /&gt;
在小世界理論中,如果送信到目標的前一步,都是經由特定的3個人,代表這三個人很重要,&lt;br /&gt;
目前social network還無法透過社群網站判斷這些人&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Social actors(群眾的智慧)&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Connectors&lt;br /&gt;
認識很多人,很擅長社交&lt;/li&gt;
  &lt;li&gt;Mavens&lt;br /&gt;
資訊專家,知道很多各式訊息&lt;/li&gt;
  &lt;li&gt;Salesman&lt;br /&gt;
容易說服別人,擅長協調&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;判斷social network的四種centrality&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Degree centrality(local)&lt;br /&gt;
點的重要性,若network的規模大小不同,做normalize(除總size-1)&lt;/li&gt;
  &lt;li&gt;Betweeness Centrality&lt;br /&gt;
Node&lt;sub&gt;i&lt;/sub&gt; A到B的shortest path有幾條經過i&lt;/li&gt;
  &lt;li&gt;Closeness Centrality
點i和所有點j的shortest path平均的距離&lt;/li&gt;
  &lt;li&gt;Eigenvector Centrality  &lt;br /&gt;
這個點的重要性,看他朋友點的重要性&lt;br /&gt;
eigenvector
    &lt;blockquote&gt;
      &lt;p&gt;一個向量乘上一個矩陣(transform),方向不變但scale可能會變&lt;br /&gt;
Ax = &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt;x&lt;br /&gt;
A矩陣代表social network關係(1:朋友關係,0:不是朋友)&lt;br /&gt;
x代表重要性&lt;br /&gt;
概念類似PageRank,page rank的值是連到他網頁的值加總&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;HIT &lt;br /&gt;
Hub&lt;br /&gt;
推薦的authoritative有多高&lt;br /&gt;
Authoritative page&lt;br /&gt;
有多少hub推薦&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;最短路徑演算法&lt;/strong&gt;&lt;br /&gt;
unweighted graph&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;BFS&lt;/li&gt;
  &lt;li&gt;Floyd-Warshall&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Group centrality&lt;/strong&gt;&lt;br /&gt;
找出social network中幾個最有影響力的人&lt;br /&gt;
或指定某幾個人想觀察這幾人的影響力&lt;/p&gt;

&lt;p&gt;group centrality一群人一起看,影響幾個人(有連線)&lt;br /&gt;
不能將每個單一人的degree加總,會有重複的&lt;/p&gt;

&lt;p&gt;Social Group Analysis
community detection algorithm&lt;/p&gt;

&lt;p&gt;Properties of cohesion&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Mutuality of ties&lt;br /&gt;
 所有subgroup彼此都有編相連,在graph中就是完全圖的概念(clique)&lt;br /&gt;
 要求有點太嚴格&lt;/li&gt;
  &lt;li&gt;Closeness or reachability of subgroup members&lt;br /&gt;
 不需要直接有邊相連,間接有相連就行了&lt;/li&gt;
  &lt;li&gt;Frquency of ties among members
 第一個是說假設有n個人必須要和n-1個人相連,那只需要和n-k個人相連就可以了&lt;/li&gt;
  &lt;li&gt;Relative frequency of ties among subgroup members compared to non-member&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Clique&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;maximal complete subgraph,最大的子圖任兩點都有邊相連&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;N-Clique 
在grahp中,任兩個點之間的距離&amp;lt;N&lt;br /&gt;
N-clan&lt;br /&gt;
必須是N-Clique&lt;br /&gt;
在subgraph中,任兩個點之間的距離&amp;lt;N
N-club
不必是N-Clique&lt;/p&gt;

&lt;p&gt;K-plex&lt;br /&gt;
如果是clique每個點的degree是n-1&lt;br /&gt;
如果是k-plex,每個點的degree是n-k&lt;br /&gt;
假設subgraph有4個點,2-plex每個點的degree至少是2&lt;/p&gt;

&lt;p&gt;K-core
至少和k個人是朋友
每個點的degree至少是k&lt;/p&gt;

&lt;p&gt;Community Detection Approaches&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Kernighan-Lin Alog(KL algorithm)&lt;/li&gt;
  &lt;li&gt;Hierarchical Clustering&lt;/li&gt;
  &lt;li&gt;Modularity Maximization&lt;/li&gt;
  &lt;li&gt;Bridge-Cut Algo&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;KL algorithm&lt;br /&gt;
有權重的圖weighted graph
input: weighted graph
output: 切成兩個subgraph且橫跨兩群的crossing(cut)的值越小越好,
切成兩半那條線橫跨的cost越小越好&lt;br /&gt;
希望群和群的相似度越大,同群的相似度越像&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;任意切成兩半&lt;/li&gt;
  &lt;li&gt;交換其中兩點使cost下降&lt;/li&gt;
  &lt;li&gt;交換直到收斂&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;external cost
    crossing的cost(連向別群的cost)
internal cost
    連向同群的cost
difference
    external cost - internal cost&lt;/p&gt;

&lt;p&gt;ab交換
Gain = Da + Db - 2Wab
Difference a + Difference b - 2*weighted ab&lt;/p&gt;

&lt;p&gt;z = crossing edge與ab無關的其他cost總和
原來crossing cost = z + Ea + Eb - Wab
交換完new crossing cost = z + la + lb + Wab&lt;/p&gt;

&lt;p&gt;交換數回合,若遇到gain是負的嘗試做交換下去,到最後再找gain最好的&lt;/p&gt;

&lt;p&gt;時間複雜度:O(n^3)&lt;/p&gt;

&lt;h4 id=&quot;reference&quot;&gt;reference&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;http://newdoc.nccu.edu.tw/teaschm/1052/schmPrv.jsp-yy=105&amp;amp;smt=2&amp;amp;num=753868&amp;amp;gop=00&amp;amp;s=1&amp;amp;tea=101583.htm&quot;&gt;社群雲端運算&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 

</feed>
