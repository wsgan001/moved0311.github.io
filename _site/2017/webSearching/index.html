<!DOCTYPE html>
<html lang="en-us">
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      WebSearching &middot; Taiyi's note
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="/public/css/custom.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">
  
  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/public/favicon.ico">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body class="theme-base-0b">
    <div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/sdk.js#xfbml=1&version=v2.8&appId=228652297542969";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>
    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Taiyi's note
        </a>
      </h1>
      <p class="lead"></p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item" href="/">Home</a>

      

      
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/Archive/">Archives</a>
          
        
      
        
          
            <a class="sidebar-nav-item" href="/about/">About</a>
          
        
      
        
      
        
          
        
      
        
          
        
      
			
	
	<li>
		<a href="https://github.com/moved0311">
		   <span class="fa-stack fa-lg">
              <i class="fa fa-circle fa-stack-2x"></i>
              <i class="fa fa-github fa-stack-1x icon"></i>
          </span>
		</a>
	</li>
	

	
	  <li>
		<a href="https://www.facebook.com/100000329876068">
		  <span class="fa-stack fa-lg">
              <i class="fa fa-circle fa-stack-2x"></i>
              <i class="fa fa-facebook fa-stack-1x icon"></i>
          </span>
		</a>
	  </li>
	

    </nav>

    <p>@ 2017</p>
  </div>
</div>


    <div class="content container">
      <div class="post">
  <h1 class="post-title">WebSearching</h1>
  <span class="post-date">07 Mar 2017</span>
  <p><strong>CH8 Evaluation in information retrival</strong>  <br />
評量search engine好壞</p>
<ol>
  <li>搜到的index</li>
  <li>搜尋速度</li>
  <li>二氧化碳排放量</li>
  <li>和搜尋相關程度</li>
</ol>

<p>相關程度</p>
<ol>
  <li>benchmark資料集</li>
  <li>benchmark queries(問句)</li>
  <li>文章是否相關的標記(ground truths)</li>
</ol>

<p>queries和information need有落差
想找的東西,不會下key word</p>

<p><strong>Precision (P)</strong></p>
<blockquote>
  <p>Precision = <script type="math/tex">\frac{檢索到相關物件的數量}{物件總數}\</script></p>
</blockquote>

<p><strong>Recall (R)</strong></p>
<blockquote>
  <p>Recall = <script type="math/tex">\frac{檢索到相關物件的數量}{相關物件總數}\</script></p>
</blockquote>

<table>
  <tbody>
    <tr>
      <td> </td>
      <td>Relevant</td>
      <td>Nonrelevent</td>
    </tr>
    <tr>
      <td>Retrieved</td>
      <td>true positive(tp)</td>
      <td>false positive(fp)</td>
    </tr>
    <tr>
      <td>Not retrieved</td>
      <td>false negatives(fn)</td>
      <td>true negatives(tn)</td>
    </tr>
  </tbody>
</table>

<p>true positive(tp) 機器判斷+且為真<br />
false positive(fp)機器判斷+但是是假<br />
false negatives(fn) 機器判斷-但判斷錯<br />
true negatives(tn)  機器判斷-且判斷對</p>

<p>P = <script type="math/tex">\frac{tp}{tp+fp}\</script></p>

<p>R = <script type="math/tex">\frac{tp}{tp+fn}\</script></p>

<p><strong>Accuracy vs Precision</strong> <br />
accuracy = <script type="math/tex">\frac{tp+tn}{tp+fp+fn+tn}\</script></p>
<blockquote>
  <p>accuracy不適合用在information retrieval,
因為通常Nonrelevant會非常的大,tn項非常大除分母fn和tn都非常大結果會趨近於1,所以才用Precision和Recall作為依據</p>
</blockquote>

<p><strong>調和平均數(harmonic mean)</strong></p>
<blockquote>
  <p>H = <script type="math/tex">\frac{n}{\frac{1}{x_1}+\frac{1}{x_2}+..+\frac{1}{x_n}}\</script></p>
</blockquote>

<p>Precision/Recall Tradoff
使用調和平均數計算Precision和Recall的Tradoff<br />
量測的數值稱做F measure,α和1-α分別為P和R的權重,一般是取α=0.5</p>
<blockquote>
  <p>F = <script type="math/tex">\frac{1}{\alpha\frac{1}{P}+(1-\alpha)\frac{1}{R}} = \frac{(\beta^2+1)PR}{\beta^2P+R}\</script> where <script type="math/tex">\ \beta^2=\frac{1-\alpha}{\alpha}\</script></p>
</blockquote>

<h4 id="ranked-evalution">Ranked Evalution</h4>
<p>P,R,F都是unordered(沒有等級)<br />
一個query會有一個Precision/Recall圖(崎嶇的坡)  <br />
使用內插法(interpolated)可以得到一張較平滑的P-R圖(和機器學習ROC curve相似)
P-R curve的面積越大效能越佳(代表Precision掉越慢)</p>

<p><strong>內插法</strong></p>
<blockquote>
  <script type="math/tex; mode=display">\ p_{interp}= \max\limits_{r'\ge r}\ p(r{'})\</script>
</blockquote>

<p>r代表recall,
作法是從目前往後找最高的點向前填平,並重新畫P-R圖</p>

<p><strong>Mean Average Precision(MAP)</strong></p>
<blockquote>
  <script type="math/tex; mode=display">\ MAP(Q) = \frac{1}{|Q|}\sum^{|Q|}_{j=1}\frac{1}{m_j}\sum_{k=1}^{m_j}Precision(R_{jk})\</script>
</blockquote>

<p>第一個sum算query平均<br />
第二個sum算precision平均</p>

<p><strong>Precision at k</strong><br />
比較第k名的Precision</p>

<p><strong>Normalized Discounted Cumulative Gain(NDCG)</strong>  <br />
作者：Kalervo Jarvelin, Jaana Kekalainen(2002)</p>

<p>G = &lt;3,2,3,0,0,1,2,2,3,0,…&gt;<br />
3高度相關, 0沒關係<br />
步驟:</p>
<ol>
  <li>Cumulative Gain(CG)</li>
  <li>Discounted Cumulative Gain(DCG)</li>
  <li>Normalized Discounted Cumulative Gain(NDCG)
    <blockquote>
      <p>得到前幾名的相關程度(1-3),除log<sub>2</sub>(rank+1),<br />
對排名做懲罰,越後面懲罰越重<br />
DCG<sub>n</sub> 前n項總和<br />
nDCG<sub>n</sub> = <script type="math/tex">\ \frac{DCG_{n}}{IDCG_{n}}(\frac{相關程度排序}{理想相關程度},做正規化)\</script></p>
    </blockquote>
  </li>
</ol>

<p><strong>benchmark 資料集</strong></p>
<ol>
  <li>Cranfield</li>
  <li>TREC(nist.gov)<br />
 Ad-hoc 資料集(1992-1999)</li>
  <li>GOV2
 2500萬篇文章</li>
  <li>NICIR
 cross-language IR</li>
  <li>Cross Language Evaluation</li>
  <li>REUTERS</li>
</ol>

<p><strong>標記資料準則</strong> <br />
Kappa measure</p>
<blockquote>
  <p>標記資料是否一致,若標記不一致資料中就沒有truth</p>
</blockquote>

<p>Kappa計算公式</p>

<p>Pooled marginals</p>

<p>A/B testing
一次有兩套演算法並存<br />
一部分流量導到新的演算法<br />
並觀察AB的差異,新的較好再導過去</p>

<p>Result Summaries</p>
<ul>
  <li>10 blue link</li>
  <li>Static/Dynamic
抽前50個字/利用nlp技術</li>
</ul>

<p>quicklinks<br />
底下多的鍊結</p>

<p><strong>Traditional Information retreval (ch11)</strong>  <br />
模型(ch6)</p>
<ol>
  <li>Vector Space model
 TF-IDF</li>
  <li>Probabilistic Information Retrieval
 BM25</li>
</ol>

<table>
  <tbody>
    <tr>
      <td>Empirical IR</td>
      <td>Model-based IR</td>
    </tr>
    <tr>
      <td>暴力法</td>
      <td>有理論模型</td>
    </tr>
    <tr>
      <td>heuristic</td>
      <td>數學假設</td>
    </tr>
    <tr>
      <td>難推廣到其他問題</td>
      <td>容易推廣到其他問題</td>
    </tr>
  </tbody>
</table>

<p>1960 第一個機率模型
1970 
vector space model 1975
classic probabilistic model
1980
non-class logic<br />
1990
TREC benchmark<br />
goolge成立1996
2000
learning to rank
Markov model</p>

<p><strong>VectorSpace.py範例程式</strong><br />
<a href="http://blog.josephwilk.net/projects/building-a-vector-space-search-engine-in-python.html">Building a Vector Space Search Engine in Python</a> <br />
將多篇文章建立一個向量模型<br />
並6輸入query,到每篇文章中做search<br />
計算Precision和Recall</p>

<p>使用到的方法</p>
<ul>
  <li>將所有文章使用join()成為一個string包含所有文章內容</li>
  <li>做string clean去除. , 多餘空白並轉為小寫</li>
  <li>將clean好的string利用空白切分成words array,丟到Porter stem(去除字尾)</li>
  <li>刪除重複的word,使用set讓出現的word唯一
    <blockquote>
      <p>Porter Stemming Algorithm
作者:Martin Porter(2006)
去除字尾</p>
    </blockquote>
  </li>
  <li>得到所有整理完的words,做成index(將每個word編號)</li>
  <li>將每篇文章分別建立自己的index,並統計每個word出現的次數</li>
  <li>將輸入的query做成vector</li>
  <li>利用內積計算相關程度</li>
</ul>

<p>Ch6 Model
Vocabulary V = {w1,w2,w3,…wv} 
Query q = q1,q2,…,qm
Document 文章 di = w1,w2,…
Collection 文章集合 C={d1,d2,d3,…}</p>

<p>Computing R(q)</p>
<ol>
  <li>Document select
挑文件1相關0不相關,挑到近似</li>
  <li>Document ranking
query的結果&gt;threshold 就收進去<br />
找到較相關,比沒有依據好</li>
</ol>

<p>Probability Ranking Principle(PRP)</p>

<p>The notation of Relevance</p>
<ul>
  <li>Relevance
    <ul>
      <li>Similarity 相似度
        <ul>
          <li>Vector space model</li>
        </ul>
      </li>
      <li>Probability of relevance 機率模型</li>
      <li>Probability inference 機率推論</li>
    </ul>
  </li>
</ul>

<p>Vector Space Model
將query和document表示成向量形式(similar representation)<br />
Relevance(d,q) = similar(d,q)
利用cosine算相似度(1 ~ -1) 
high dimension 
good dimension -&gt; orthogonal<br />
Empirically effective
實作容易</p>

<p>Linear independent</p>

<p>LDA</p>

<p>TF(Term Frequency)
	word count
IDF(Inverse Document Frequency)(反向的TF)
	字的獨特性
	the,a,to IDF值很低(沒有鑑別度)	
	IDF(t) = 1 + log(n/k)  n篇數 k字出現次數</p>

<p>TF-IDF 
	weight(t,d) = TF(w,d) * IDF</p>

<p>Ch11</p>


</div>

<div class="related">
  <h2>Related Posts</h2>
  <ul class="related-posts">
    
      <li>
        <h3>
          <a href="/2017/python/">
            python
            <small>08 Mar 2017</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/2017/paperWrite/">
            paperWrite
            <small>07 Mar 2017</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/2017/xml/">
            xml
            <small>06 Mar 2017</small>
          </a>
        </h3>
      </li>
    
  </ul>

  
    <div class="fb-comments" data-href="http://localhost:4000/2017/webSearching/" data-width="auto" data-numposts="5"></div>

  
</div>

    </div>

  </body>
</html>
